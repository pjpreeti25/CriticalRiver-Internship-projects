{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LLM-Based Biomedical Data Summarization\n"
      ],
      "metadata": {
        "id": "mYWYO9jyAWpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8BkeQDdHFKab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install needed packages (run this once)\n",
        "!pip install langchain langchain-community transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XUpEuOxmWq-",
        "outputId": "568188fb-7c28-4c46-d03b-dc986a9906b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.67)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformers — Hugging Face’s library for working with state-of-the-art pre-trained language models like BioGPT."
      ],
      "metadata": {
        "id": "zrH3xPW3BzMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Write mock_api.py\n",
        "mock_api_code = '''\n",
        "import json\n",
        "\n",
        "def get_benchling_eln_entries(query=\"compound\"):\n",
        "    entries = [\n",
        "        {\n",
        "            \"id\": \"eln_001\",\n",
        "            \"title\": \"Transfection with Compound 9831\",\n",
        "            \"createdAt\": \"2024-06-21T15:30:00Z\",\n",
        "            \"content\": \"HEK293T cells treated with compound 9831 at 10 µM. 85% inhibition. Moderate cytotoxicity.\",\n",
        "            \"author\": \"Dr. Maya Singh\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"eln_002\",\n",
        "            \"title\": \"Dose Response Study for Compound 9831\",\n",
        "            \"createdAt\": \"2024-06-24T12:00:00Z\",\n",
        "            \"content\": \"Compound 9831 tested at 1, 10, 50 µM. IC50 = 8.2 µM. Minimal off-target effects.\",\n",
        "            \"author\": \"Dr. Ravi Kumar\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"eln_003\",\n",
        "            \"title\": \"Compound 9831 on SH-SY5Y Cells\",\n",
        "            \"createdAt\": \"2024-06-28T09:15:00Z\",\n",
        "            \"content\": \"No inhibition on SH-SY5Y cells. Likely cell-line specific effect.\",\n",
        "            \"author\": \"Dr. Maya Singh\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"eln_004\",\n",
        "            \"title\": \"Compound 5291 Initial Trial\",\n",
        "            \"createdAt\": \"2024-06-30T10:00:00Z\",\n",
        "            \"content\": \"Compound 5291 tested on A549 cells. 40% inhibition at 20 µM. Stable response.\",\n",
        "            \"author\": \"Dr. Wei Zhang\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"eln_005\",\n",
        "            \"title\": \"IC50 of Compound 5291\",\n",
        "            \"createdAt\": \"2024-07-01T13:00:00Z\",\n",
        "            \"content\": \"Dose response of Compound 5291 gives IC50 = 22 µM. No cytotoxicity observed.\",\n",
        "            \"author\": \"Dr. Wei Zhang\"\n",
        "        },\n",
        "    ]\n",
        "    return [e for e in entries if query.lower() in e[\"title\"].lower() or query.lower() in e[\"content\"].lower()]\n",
        "\n",
        "def get_cdd_compound_info(compound_name=\"compound\"):\n",
        "    compounds = [\n",
        "        {\n",
        "            \"compound_id\": \"cmpd_9831\",\n",
        "            \"name\": \"Compound 9831\",\n",
        "            \"structure\": \"CC1=CC(=O)NC(C)=C1\",\n",
        "            \"assays\": [\n",
        "                {\"assay_id\": \"a_001\", \"title\": \"HEK293T Inhibition\", \"result\": \"85\", \"units\": \"%\", \"dose\": \"10 µM\"},\n",
        "                {\"assay_id\": \"a_002\", \"title\": \"IC50 HEK293T\", \"result\": \"8.2\", \"units\": \"µM\", \"dose\": \"1-50 µM\"},\n",
        "                {\"assay_id\": \"a_003\", \"title\": \"CYP450 Off-target\", \"result\": \"Low\", \"units\": \"qualitative\"}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"compound_id\": \"cmpd_5291\",\n",
        "            \"name\": \"Compound 5291\",\n",
        "            \"structure\": \"CC(C)C1=CC=CC=C1\",\n",
        "            \"assays\": [\n",
        "                {\"assay_id\": \"a_004\", \"title\": \"A549 Inhibition\", \"result\": \"40\", \"units\": \"%\", \"dose\": \"20 µM\"},\n",
        "                {\"assay_id\": \"a_005\", \"title\": \"IC50 A549\", \"result\": \"22\", \"units\": \"µM\", \"dose\": \"1-100 µM\"}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "    return [c for c in compounds if compound_name.lower() in c[\"name\"].lower()]\n",
        "'''\n",
        "with open(\"mock_api.py\", \"w\") as f:\n",
        "    f.write(mock_api_code)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xlxs86ngocif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates a Python file named mock_api.py that simulates (mocks) two APIs providing biomedical data:\n",
        "\n",
        "`get_benchling_eln_entries(query)`:\n",
        "Returns a filtered list of mock Electronic Lab Notebook (ELN) entries that mention the given query in their title or content. These entries simulate experimental notes related to compounds, including details like cell tests, inhibition percentages, IC50 values, and authorship.\n",
        "\n",
        "`get_cdd_compound_info(compound_name)`:\n",
        "Returns a filtered list of mock compound data from a Chemical Data Database (CDD). Each compound record includes its ID, name, chemical structure (as a string), and associated assay results like inhibition percentages, IC50 values, and off-target effects."
      ],
      "metadata": {
        "id": "IyeRhuRjEdNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This mock API lets your code fetch example experimental and assay data without needing a real external service.\n",
        "It helps you develop and test your summarization pipeline with consistent, predictable data."
      ],
      "metadata": {
        "id": "piZPR_58FBd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For better understanding (Preeti):\n",
        "\n",
        "Why do we use an API, even if the data is defined in JSON inside your code:\n",
        "\n",
        "**Modularity & Abstraction**: The API functions hide the details of how data is stored or fetched. Your main code just “asks” the API for data without worrying about where it comes from.\n",
        "\n",
        "**Simulating Real-world Use**: In real projects, data usually lives on servers or databases and you access it via APIs. Using mock APIs helps you develop and test your code as if you’re working with a real external service.\n",
        "\n",
        "**Easier Updates & Maintenance**: If the data changes or grows, you only need to update it inside the API functions, not throughout your whole codebase.\n",
        "\n",
        "**Reusability**: APIs let you reuse the same data retrieval logic in different parts of your project or even in other projects."
      ],
      "metadata": {
        "id": "7gUWypxFFDCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chat_code = '''\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "#1. Load BioGPT model and tokenizer\n",
        "model_name = \"microsoft/BioGPT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "#2. Build HF text-generation pipeline\n",
        "hf_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False,\n",
        ")\n",
        "\n",
        "#3. Wrap the pipeline with LangChain's LLM interface\n",
        "pipe = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "#4. Define prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"eln\", \"cdd\"],\n",
        "    template=(\n",
        "        \"You are a biomedical assistant. Summarize the compound's performance using the data below.\\\\n\"\n",
        "        \"ELN entries:\\\\n{eln}\\\\n\\\\n\"\n",
        "        \"CDD data:\\\\n{cdd}\\\\n\\\\n\"\n",
        "        \"Summary:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "#5. Create the LLMChain\n",
        "chain = LLMChain(llm=pipe, prompt=prompt_template)\n",
        "\n",
        "#6. Helper function to clean and format input data\n",
        "def summarize_data(eln_entries, cdd_data):\n",
        "    eln_str = \"\\\\n\".join([f\"{e['title']}: {e['content']}\" for e in eln_entries])\n",
        "    cdd_str = \"\\\\n\".join([\n",
        "        f\"{c['name']}:\\\\n\" + \"\\\\n\".join([f\"- {a['title']}: {a['result']} {a['units']}\" for a in c[\"assays\"]])\n",
        "        for c in cdd_data\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "        return chain.invoke({\"eln\": eln_str, \"cdd\": cdd_str})\n",
        "    except Exception as e:\n",
        "        return f\"[Error during summarization: {e}]\"\n",
        "'''\n",
        "\n",
        "with open(\"llm_chat.py\", \"w\") as f:\n",
        "    f.write(llm_chat_code)\n"
      ],
      "metadata": {
        "id": "3hH9w72Kozxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file creates a reusable tool that takes experimental data, asks BioGPT to summarize it, and gives you a natural-language result. It sets up everything needed for this — model loading, formatting, prompting, and running — all in one place."
      ],
      "metadata": {
        "id": "V19PTvb7GIUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loads the BioGPT model and tokenizer — designed for biomedical text generation. Causal LM is Causal Language modeling used for predicting next word.\n",
        "\n",
        "2. This line builds a text-generation engine using your model and tokenizer, and customizes how much it writes, how random it is, and what part of the output you see.\n",
        "\n",
        "3. This line turns your Hugging Face model (`hf_pipeline`) into a LangChain-compatible LLM object so you can use it in LangChain’s powerful chains and prompting frameworks.\n",
        "\n",
        "4.  This code defines a reusable template that combines ELN and CDD data into a clear, consistent prompt for the LLM to generate a scientific summary. LLMs like GPT or BioGPT don’t “just know” what to do — they rely heavily on prompt engineering.\n"
      ],
      "metadata": {
        "id": "cWN3ry4sGLM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. It creates a chain that will:\n",
        "Take ELN + CDD data as input;\n",
        "Format them using your prompt_template;\n",
        "Pass the full prompt to your model;\n",
        "Return the model’s generated summary text\n",
        "\n",
        "6. This function formats ELN and CDD data into text, sends it to the language model chain for summarization, and returns the summary or an error if something goes wrong."
      ],
      "metadata": {
        "id": "fBgNLfHyLo8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sacremoses\n",
        "\n",
        "# Step 4: Import and run the summarization inline\n",
        "from mock_api import get_benchling_eln_entries, get_cdd_compound_info\n",
        "from llm_chat import summarize_data\n",
        "\n",
        "compound_name = \"compound 9831\"\n",
        "eln_data = get_benchling_eln_entries(compound_name)\n",
        "cdd_data = get_cdd_compound_info(compound_name)\n",
        "\n",
        "print(\"=== ELN Data ===\")\n",
        "for e in eln_data:\n",
        "    print(f\"- {e['title']}: {e['content']}\")\n",
        "\n",
        "print(\"\\n=== CDD Data ===\")\n",
        "for c in cdd_data:\n",
        "    print(f\"- {c['name']} assays:\")\n",
        "    for a in c[\"assays\"]:\n",
        "        print(f\"  * {a['title']} = {a['result']} {a['units']}\")\n",
        "\n",
        "print(\"\\n=== LLM Summary ===\")\n",
        "print(summarize_data(eln_data, cdd_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ0_lwfKo0xh",
        "outputId": "e2df2ec9-2d5e-4dc4-83d8-aa5bdf91df54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/content/llm_chat.py:23: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  pipe = HuggingFacePipeline(pipeline=hf_pipeline)\n",
            "/content/llm_chat.py:37: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ELN Data ===\n",
            "- Transfection with Compound 9831: HEK293T cells treated with compound 9831 at 10 µM. 85% inhibition. Moderate cytotoxicity.\n",
            "- Dose Response Study for Compound 9831: Compound 9831 tested at 1, 10, 50 µM. IC50 = 8.2 µM. Minimal off-target effects.\n",
            "- Compound 9831 on SH-SY5Y Cells: No inhibition on SH-SY5Y cells. Likely cell-line specific effect.\n",
            "\n",
            "=== CDD Data ===\n",
            "- Compound 9831 assays:\n",
            "  * HEK293T Inhibition = 85 %\n",
            "  * IC50 HEK293T = 8.2 µM\n",
            "  * CYP450 Off-target = Low qualitative\n",
            "\n",
            "=== LLM Summary ===\n",
            "{'eln': 'Transfection with Compound 9831: HEK293T cells treated with compound 9831 at 10 µM. 85% inhibition. Moderate cytotoxicity.\\nDose Response Study for Compound 9831: Compound 9831 tested at 1, 10, 50 µM. IC50 = 8.2 µM. Minimal off-target effects.\\nCompound 9831 on SH-SY5Y Cells: No inhibition on SH-SY5Y cells. Likely cell-line specific effect.', 'cdd': 'Compound 9831:\\n- HEK293T Inhibition: 85 %\\n- IC50 HEK293T: 8.2 µM\\n- CYP450 Off-target: Low qualitative', 'text': ' In summary, compound 9831 is a safe and potent small molecule for in vitro use.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###About the code:\n",
        "\n",
        "This code block fetches mock experimental and assay data for a compound, displays the raw data, and then produces a natural language summary of that data using a biomedical language model. It demonstrates an end-to-end workflow from data retrieval to AI-powered summarization."
      ],
      "metadata": {
        "id": "i8rhM0mTMouY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###About the output:\n",
        "\n",
        "The summary is returned as a dictionary containing:\n",
        "\n",
        "`eln`: The raw concatenated ELN text input.\n",
        "\n",
        "`cdd`: The raw concatenated CDD assay text input.\n",
        "\n",
        "`text`: The generated summary by the language model, which says:\n",
        "\n",
        "\"In summary, compound 9831 is a safe and potent small molecule for in vitro use.\""
      ],
      "metadata": {
        "id": "md5uYKHxMsGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Till now, we worked on : generating a summary by the language model (BioGPT) for that particular compund"
      ],
      "metadata": {
        "id": "h8gV93D4ObGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code using ChatGPT"
      ],
      "metadata": {
        "id": "JCD-7E_mhJ-C"
      }
    }
  ]
}